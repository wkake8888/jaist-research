**Title**\
The Influence of Data Pre-processing and Post-processing on Long Document Summarization
https://arxiv.org/pdf/2112.01660.pdf

**Problem**
- Transformers are not suited for processing long documents, due to their quadratically increasing memory and time consumption.
- Simply truncating a long document or applying the sparse attention mechanism will incur the context fragmentation problem or lead to an inferior modeling capability against comparable model sizes.

