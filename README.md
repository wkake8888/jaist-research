research plan
=======
2.23 - 3.16 read paper
------
**week 1 : (2.23 - 3.2)**

**week 2 : (3.2 - 3.9)**

**week 3 : (3.9 - 3.16)**

four paper for a week at least

3.17 -    experiment
------
**data-preprocess:**

data-example
--------
https://drive.google.com/file/d/1AgZjpvZZLv_vzTUCixwekii_H3AaP2HD/view?usp=sharing

XIONG: 
=====
**Hierarchical Network**:

(EMNLP2020)A Hierarchical Network for Abstractive Meeting Summarization with Cross-Domain Pretraining
https://github.com/microsoft/HMNet

(EMNLP2019)Neural Extractive Text Summarization with Syntactic Compression 

(EMNLP2020) Unsupervised Extractive Summarization by Pre-training Hierarchical Transformers
https://github.com/xssstory/STAS
 
(ACL2022)HiStruct+: Improving Extractive Text Summarization with Hierarchical Structure Information
https://github.com/QianRuan/histruct

https://github.com/nlpyang/PreSumm

(EMNLP-IJCNLP 2019)Extractive summarization of Long Documents by combining local context and global context'
https://github.com/Wendy-Xiao/Extsumm_local_global_context

**data prepro**
SciBERTSUM: Extractive Summarization for Scientific Documents
https://github.com/atharsefid/SciBERTSUM

kake:
====
- max_sentences is hyperparameter. fixed number. (from HiBert)
- Max_position = Max tokens in a source document. (from HiBert)
- Max_tokens = Max tokens in a batch. (from HiBert)\
HiBert: https://xingxingzhang.github.io/hibert.html \
Note:\
About mini batch, batch size: https://www.kaggle.com/code/residentmario/full-batch-mini-batch-and-online-learning/notebook \
Naist sort, shuffle: https://aclanthology.org/W17-3208.pdf \

Hierarchical Pooling: https://github.com/HeapHop30/hierarchical-pooling/blob/master/core/Hierarchical%20pooling.ipynb \
3.17 - 4.28 experiment
------------------

4.29 - 5.17 paper writing
-------------------------

